# Main Hydra Configuration
defaults:
  - model: bert  # or: modernbert

# Hydra Configuration
hydra:
  run:
    dir: outputs

# Training Configuration (default)
train:
  epochs: 5
  batch_size: 8
  learning_rate: 5e-5
  optimizer: "adam"
  scheduler: "constant"
  warmup_steps: 0
  seed: 42
  device: "cuda"

# Data Configuration
data:
  dataset_name: "stanfordnlp/imdb"
  max_len: 128
  valid_size: 0.1
  test_size: 0.1
  
# Logging Configuration
logging:
  wandb_project: "nlp_imdb_classification"
  wandb_entity: null
  log_dir: "logs"
  checkpoint_dir: "checkpoints"
  save_interval: 100
  log_interval: 50

# Evaluation Configuration
eval:
  batch_size: 32
  eval_interval: 100
